// RAG Engine - æ£€ç´¢å¢å¼ºç”Ÿæˆç³»ç»Ÿ
// Retrieval-Augmented Generation for AI responses
//
// æ ¸å¿ƒåŠŸèƒ½ï¼š
// 1. å‘é‡æ•°æ®åº“é›†æˆï¼ˆQdrant/Milvusï¼‰
// 2. æ–‡æ¡£åˆ†å—å’ŒåµŒå…¥
// 3. è¯­ä¹‰æ£€ç´¢
// 4. ä¸Šä¸‹æ–‡æ³¨å…¥
// 5. æ··åˆæ£€ç´¢ï¼ˆå‘é‡+å…³é”®è¯ï¼‰

use anyhow::{anyhow, Result};
use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::sync::Arc;
use tokio::sync::RwLock;
use tracing::{info, warn};

/// æ–‡æ¡£åˆ†å—ç­–ç•¥
#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
pub enum ChunkingStrategy {
    /// å›ºå®šå¤§å°åˆ†å—
    FixedSize,
    /// è¯­ä¹‰åˆ†å—ï¼ˆæŒ‰æ®µè½/å¥å­ï¼‰
    Semantic,
    /// æ»‘åŠ¨çª—å£
    SlidingWindow,
    /// é€’å½’åˆ†å—
    Recursive,
}

/// åµŒå…¥æ¨¡å‹ç±»å‹
#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
pub enum EmbeddingModel {
    /// OpenAI text-embedding-3-small
    OpenAISmall,
    /// OpenAI text-embedding-3-large
    OpenAILarge,
    /// æœ¬åœ°æ¨¡å‹ï¼ˆall-MiniLM-L6-v2ï¼‰
    LocalMiniLM,
    /// è‡ªå®šä¹‰æ¨¡å‹
    Custom,
}

/// æ£€ç´¢æ¨¡å¼
#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
pub enum RetrievalMode {
    /// çº¯å‘é‡æ£€ç´¢
    VectorOnly,
    /// çº¯å…³é”®è¯æ£€ç´¢
    KeywordOnly,
    /// æ··åˆæ£€ç´¢
    Hybrid,
}

/// æ–‡æ¡£å—
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DocumentChunk {
    /// å—ID
    pub chunk_id: String,
    /// åŸå§‹æ–‡æ¡£ID
    pub document_id: String,
    /// å—å†…å®¹
    pub content: String,
    /// å—ç´¢å¼•ï¼ˆåœ¨æ–‡æ¡£ä¸­çš„ä½ç½®ï¼‰
    pub chunk_index: usize,
    /// å…ƒæ•°æ®
    pub metadata: HashMap<String, String>,
    /// åµŒå…¥å‘é‡ï¼ˆbase64ç¼–ç ï¼‰
    pub embedding: Option<String>,
    /// åˆ›å»ºæ—¶é—´
    pub created_at: DateTime<Utc>,
}

/// æ–‡æ¡£
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Document {
    /// æ–‡æ¡£ID
    pub document_id: String,
    /// æ–‡æ¡£æ ‡é¢˜
    pub title: String,
    /// æ–‡æ¡£å†…å®¹
    pub content: String,
    /// æ–‡æ¡£ç±»å‹ï¼ˆmarkdown/pdf/txt/codeï¼‰
    pub doc_type: String,
    /// å…ƒæ•°æ®
    pub metadata: HashMap<String, String>,
    /// åˆ›å»ºæ—¶é—´
    pub created_at: DateTime<Utc>,
    /// æ›´æ–°æ—¶é—´
    pub updated_at: DateTime<Utc>,
}

/// æ£€ç´¢ç»“æœ
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RetrievalResult {
    /// æ–‡æ¡£å—
    pub chunk: DocumentChunk,
    /// ç›¸ä¼¼åº¦åˆ†æ•°ï¼ˆ0.0-1.0ï¼‰
    pub score: f64,
    /// æ£€ç´¢æ–¹æ³•
    pub retrieval_method: String,
}

/// RAGé…ç½®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RagConfig {
    /// åµŒå…¥æ¨¡å‹
    pub embedding_model: EmbeddingModel,
    /// åˆ†å—ç­–ç•¥
    pub chunking_strategy: ChunkingStrategy,
    /// å—å¤§å°ï¼ˆå­—ç¬¦æ•°ï¼‰
    pub chunk_size: usize,
    /// å—é‡å ï¼ˆå­—ç¬¦æ•°ï¼‰
    pub chunk_overlap: usize,
    /// æ£€ç´¢æ¨¡å¼
    pub retrieval_mode: RetrievalMode,
    /// Top-Kç»“æœæ•°
    pub top_k: usize,
    /// æœ€å°ç›¸ä¼¼åº¦é˜ˆå€¼
    pub min_similarity: f64,
    /// å‘é‡æ•°æ®åº“URL
    pub vector_db_url: String,
}

impl Default for RagConfig {
    fn default() -> Self {
        Self {
            embedding_model: EmbeddingModel::OpenAISmall,
            chunking_strategy: ChunkingStrategy::Semantic,
            chunk_size: 512,
            chunk_overlap: 50,
            retrieval_mode: RetrievalMode::Hybrid,
            top_k: 5,
            min_similarity: 0.7,
            vector_db_url: "http://localhost:6333".to_string(), // Qdranté»˜è®¤ç«¯å£
        }
    }
}

/// RAGç»Ÿè®¡
#[derive(Debug, Clone, Default, Serialize, Deserialize)]
pub struct RagStats {
    pub total_documents: u64,
    pub total_chunks: u64,
    pub total_queries: u64,
    pub avg_query_time_ms: f64,
    pub cache_hits: u64,
    pub cache_misses: u64,
}

/// RAGå¼•æ“
pub struct RagEngine {
    config: RagConfig,
    /// æ–‡æ¡£å­˜å‚¨
    documents: Arc<RwLock<HashMap<String, Document>>>,
    /// å—å­˜å‚¨
    chunks: Arc<RwLock<HashMap<String, DocumentChunk>>>,
    /// æŸ¥è¯¢ç¼“å­˜
    query_cache: Arc<RwLock<HashMap<String, Vec<RetrievalResult>>>>,
    /// ç»Ÿè®¡ä¿¡æ¯
    stats: Arc<RwLock<RagStats>>,
}

impl RagEngine {
    /// åˆ›å»ºæ–°çš„RAGå¼•æ“
    pub fn new(config: RagConfig) -> Self {
        info!("ğŸ” Initializing RAG Engine");
        info!("    Embedding Model: {:?}", config.embedding_model);
        info!("    Chunking: {:?} (size: {}, overlap: {})",
            config.chunking_strategy, config.chunk_size, config.chunk_overlap);
        info!("    Retrieval Mode: {:?}", config.retrieval_mode);
        info!("    Top-K: {}", config.top_k);

        Self {
            config,
            documents: Arc::new(RwLock::new(HashMap::new())),
            chunks: Arc::new(RwLock::new(HashMap::new())),
            query_cache: Arc::new(RwLock::new(HashMap::new())),
            stats: Arc::new(RwLock::new(RagStats::default())),
        }
    }

    /// ç´¢å¼•æ–‡æ¡£
    pub async fn index_document(&self, document: Document) -> Result<Vec<String>> {
        info!("ğŸ“„ Indexing document: {}", document.title);

        // åˆ†å—
        let chunks = self.chunk_document(&document).await?;
        let chunk_ids: Vec<String> = chunks.iter().map(|c| c.chunk_id.clone()).collect();

        // ç”ŸæˆåµŒå…¥
        for mut chunk in chunks {
            let embedding = self.generate_embedding(&chunk.content).await?;
            chunk.embedding = Some(embedding);

            // å­˜å‚¨å—
            let mut chunks_store = self.chunks.write().await;
            chunks_store.insert(chunk.chunk_id.clone(), chunk);
        }

        // å­˜å‚¨æ–‡æ¡£
        let mut docs = self.documents.write().await;
        docs.insert(document.document_id.clone(), document);

        // æ›´æ–°ç»Ÿè®¡
        let mut stats = self.stats.write().await;
        stats.total_documents += 1;
        stats.total_chunks += chunk_ids.len() as u64;

        info!("âœ… Indexed {} chunks", chunk_ids.len());
        Ok(chunk_ids)
    }

    /// æ£€ç´¢ç›¸å…³æ–‡æ¡£
    pub async fn retrieve(&self, query: &str) -> Result<Vec<RetrievalResult>> {
        let start = std::time::Instant::now();

        // æ£€æŸ¥ç¼“å­˜
        let cache_key = self.compute_cache_key(query);
        {
            let cache = self.query_cache.read().await;
            if let Some(cached) = cache.get(&cache_key) {
                let mut stats = self.stats.write().await;
                stats.cache_hits += 1;
                info!("ğŸ’¨ Cache hit for query");
                return Ok(cached.clone());
            }
        }

        // ç”ŸæˆæŸ¥è¯¢åµŒå…¥
        let query_embedding = self.generate_embedding(query).await?;

        // æ‰§è¡Œæ£€ç´¢
        let results = match self.config.retrieval_mode {
            RetrievalMode::VectorOnly => {
                self.vector_search(&query_embedding).await?
            }
            RetrievalMode::KeywordOnly => {
                self.keyword_search(query).await?
            }
            RetrievalMode::Hybrid => {
                self.hybrid_search(query, &query_embedding).await?
            }
        };

        // è¿‡æ»¤ä½åˆ†ç»“æœ
        let filtered: Vec<RetrievalResult> = results
            .into_iter()
            .filter(|r| r.score >= self.config.min_similarity)
            .take(self.config.top_k)
            .collect();

        // ç¼“å­˜ç»“æœ
        {
            let mut cache = self.query_cache.write().await;
            cache.insert(cache_key, filtered.clone());
        }

        // æ›´æ–°ç»Ÿè®¡
        let elapsed = start.elapsed().as_millis() as f64;
        let mut stats = self.stats.write().await;
        stats.total_queries += 1;
        stats.cache_misses += 1;
        stats.avg_query_time_ms =
            (stats.avg_query_time_ms * (stats.total_queries - 1) as f64 + elapsed)
            / stats.total_queries as f64;

        info!("ğŸ” Retrieved {} results in {:.2}ms", filtered.len(), elapsed);
        Ok(filtered)
    }

    /// æ„å»ºå¢å¼ºä¸Šä¸‹æ–‡
    pub async fn build_augmented_context(
        &self,
        query: &str,
        system_prompt: &str,
    ) -> Result<String> {
        let results = self.retrieve(query).await?;

        if results.is_empty() {
            return Ok(system_prompt.to_string());
        }

        let mut context = String::from(system_prompt);
        context.push_str("\n\n## å‚è€ƒä¸Šä¸‹æ–‡\n\n");

        for (i, result) in results.iter().enumerate() {
            context.push_str(&format!(
                "### æ¥æº {} (ç›¸ä¼¼åº¦: {:.2}%)\n{}\n\n",
                i + 1,
                result.score * 100.0,
                result.chunk.content
            ));
        }

        context.push_str("è¯·åŸºäºä»¥ä¸Šä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ï¼Œå¦‚æœä¸Šä¸‹æ–‡ä¸ç›¸å…³ï¼Œè¯·è¯´æ˜å¹¶ç»™å‡ºä½ çš„æœ€ä½³å›ç­”ã€‚");

        Ok(context)
    }

    /// åˆ é™¤æ–‡æ¡£
    pub async fn delete_document(&self, document_id: &str) -> Result<()> {
        // åˆ é™¤æ–‡æ¡£
        let mut docs = self.documents.write().await;
        docs.remove(document_id);

        // åˆ é™¤ç›¸å…³å—
        let mut chunks = self.chunks.write().await;
        chunks.retain(|_, chunk| chunk.document_id != document_id);

        // æ¸…é™¤ç¼“å­˜
        let mut cache = self.query_cache.write().await;
        cache.clear();

        info!("ğŸ—‘ï¸  Deleted document: {}", document_id);
        Ok(())
    }

    /// è·å–ç»Ÿè®¡ä¿¡æ¯
    pub async fn get_stats(&self) -> RagStats {
        self.stats.read().await.clone()
    }

    // ===== å†…éƒ¨æ–¹æ³• =====

    /// æ–‡æ¡£åˆ†å—
    async fn chunk_document(&self, document: &Document) -> Result<Vec<DocumentChunk>> {
        let mut chunks = Vec::new();

        match self.config.chunking_strategy {
            ChunkingStrategy::FixedSize => {
                let content = &document.content;
                let chunk_size = self.config.chunk_size;
                let overlap = self.config.chunk_overlap;

                let mut start = 0;
                let mut chunk_index = 0;

                while start < content.len() {
                    let end = (start + chunk_size).min(content.len());
                    let chunk_content = content[start..end].to_string();

                    chunks.push(DocumentChunk {
                        chunk_id: format!("{}_{}", document.document_id, chunk_index),
                        document_id: document.document_id.clone(),
                        content: chunk_content,
                        chunk_index,
                        metadata: document.metadata.clone(),
                        embedding: None,
                        created_at: Utc::now(),
                    });

                    start += chunk_size - overlap;
                    chunk_index += 1;
                }
            }

            ChunkingStrategy::Semantic => {
                // TODO: å®ç°è¯­ä¹‰åˆ†å—ï¼ˆæŒ‰æ®µè½/å¥å­ï¼‰
                // ç®€åŒ–å®ç°ï¼šæŒ‰æ®µè½åˆ†å—
                let paragraphs: Vec<&str> = document.content.split("\n\n").collect();
                for (i, para) in paragraphs.iter().enumerate() {
                    if para.trim().is_empty() {
                        continue;
                    }

                    chunks.push(DocumentChunk {
                        chunk_id: format!("{}_{}", document.document_id, i),
                        document_id: document.document_id.clone(),
                        content: para.to_string(),
                        chunk_index: i,
                        metadata: document.metadata.clone(),
                        embedding: None,
                        created_at: Utc::now(),
                    });
                }
            }

            _ => {
                // å…¶ä»–ç­–ç•¥å¾…å®ç°
                warn!("âš ï¸  Chunking strategy {:?} not implemented, using FixedSize", self.config.chunking_strategy);
            }
        }

        Ok(chunks)
    }

    /// ç”ŸæˆåµŒå…¥å‘é‡
    async fn generate_embedding(&self, text: &str) -> Result<String> {
        // TODO: å®é™…è°ƒç”¨åµŒå…¥API
        // æ ¹æ® embedding_model è°ƒç”¨å¯¹åº”APIï¼š
        // - OpenAI: openai.embeddings.create()
        // - Local: ä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼ˆå¦‚ rust-bertï¼‰

        // Placeholder: è¿”å›æ¨¡æ‹ŸåµŒå…¥ï¼ˆbase64ç¼–ç çš„éšæœºå‘é‡ï¼‰
        let placeholder = format!("embedding_{}", text.len());
        Ok(placeholder)
    }

    /// å‘é‡æ£€ç´¢
    async fn vector_search(&self, _query_embedding: &str) -> Result<Vec<RetrievalResult>> {
        // TODO: å®é™…å‘é‡æ•°æ®åº“æŸ¥è¯¢ï¼ˆQdrant/Milvusï¼‰
        // è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦å¹¶æ’åº

        // Placeholder
        Ok(Vec::new())
    }

    /// å…³é”®è¯æ£€ç´¢
    async fn keyword_search(&self, query: &str) -> Result<Vec<RetrievalResult>> {
        let chunks = self.chunks.read().await;
        let query_lower = query.to_lowercase();

        let mut results: Vec<RetrievalResult> = chunks
            .values()
            .filter(|chunk| chunk.content.to_lowercase().contains(&query_lower))
            .map(|chunk| RetrievalResult {
                chunk: chunk.clone(),
                score: 0.8, // ç®€åŒ–è¯„åˆ†
                retrieval_method: "keyword".to_string(),
            })
            .collect();

        results.sort_by(|a, b| b.score.partial_cmp(&a.score).unwrap());
        Ok(results)
    }

    /// æ··åˆæ£€ç´¢
    async fn hybrid_search(&self, query: &str, query_embedding: &str) -> Result<Vec<RetrievalResult>> {
        // ç»“åˆå‘é‡æ£€ç´¢å’Œå…³é”®è¯æ£€ç´¢
        let vector_results = self.vector_search(query_embedding).await?;
        let keyword_results = self.keyword_search(query).await?;

        // TODO: å®ç°ç»“æœèåˆå’Œé‡æ’åº
        // ç®€åŒ–å®ç°ï¼šåˆå¹¶ç»“æœ
        let mut combined = vector_results;
        combined.extend(keyword_results);

        // å»é‡
        combined.sort_by(|a, b| b.score.partial_cmp(&a.score).unwrap());
        combined.dedup_by(|a, b| a.chunk.chunk_id == b.chunk.chunk_id);

        Ok(combined)
    }

    fn compute_cache_key(&self, query: &str) -> String {
        // TODO: ä½¿ç”¨æ›´å¥½çš„å“ˆå¸Œï¼ˆå¦‚blake3ï¼‰
        format!("query_{}", query.len())
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_document_indexing() {
        let engine = RagEngine::new(RagConfig::default());

        let doc = Document {
            document_id: "doc1".to_string(),
            title: "Test Document".to_string(),
            content: "This is a test document.\n\nIt has multiple paragraphs.".to_string(),
            doc_type: "txt".to_string(),
            metadata: HashMap::new(),
            created_at: Utc::now(),
            updated_at: Utc::now(),
        };

        let chunk_ids = engine.index_document(doc).await.unwrap();
        assert!(!chunk_ids.is_empty());
    }

    #[tokio::test]
    async fn test_keyword_search() {
        let engine = RagEngine::new(RagConfig {
            retrieval_mode: RetrievalMode::KeywordOnly,
            ..Default::default()
        });

        let doc = Document {
            document_id: "doc1".to_string(),
            title: "Rust Programming".to_string(),
            content: "Rust is a systems programming language.".to_string(),
            doc_type: "txt".to_string(),
            metadata: HashMap::new(),
            created_at: Utc::now(),
            updated_at: Utc::now(),
        };

        engine.index_document(doc).await.unwrap();

        let results = engine.retrieve("Rust").await.unwrap();
        assert!(!results.is_empty());
    }
}
