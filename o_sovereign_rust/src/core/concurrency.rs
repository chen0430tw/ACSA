// Concurrency & Distributed Support - å¤šçº¿ç¨‹å’Œåˆ†å¸ƒå¼æ”¯æŒ
// ç›®æ ‡ï¼šé«˜æ€§èƒ½å¹¶å‘å¤„ç†å’Œåˆ†å¸ƒå¼ä»»åŠ¡è°ƒåº¦
//
// æ ¸å¿ƒåŠŸèƒ½ï¼š
// 1. å¤šçº¿ç¨‹ä»»åŠ¡æ± ï¼šåŸºäºtokioçš„å¼‚æ­¥ä»»åŠ¡è°ƒåº¦
// 2. å·¥ä½œçªƒå–ï¼šè‡ªåŠ¨è´Ÿè½½å‡è¡¡
// 3. åˆ†å¸ƒå¼é”ï¼šè·¨è¿›ç¨‹ä»»åŠ¡åè°ƒ
// 4. ä»»åŠ¡é˜Ÿåˆ—ï¼šä¼˜å…ˆçº§é˜Ÿåˆ— + å…¬å¹³è°ƒåº¦
// 5. èƒŒå‹æ§åˆ¶ï¼šé˜²æ­¢ç³»ç»Ÿè¿‡è½½

use std::collections::{HashMap, VecDeque};
use std::sync::Arc;
use tokio::sync::{RwLock, Semaphore, Mutex as TokioMutex};
use tokio::task::JoinHandle;
use anyhow::{anyhow, Result};
use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use tracing::{debug, error, info, warn};

/// å¹¶å‘é…ç½®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ConcurrencyConfig {
    pub max_concurrent_tasks: usize,    // æœ€å¤§å¹¶å‘ä»»åŠ¡æ•°
    pub worker_threads: usize,           // å·¥ä½œçº¿ç¨‹æ•°
    pub enable_work_stealing: bool,      // å¯ç”¨å·¥ä½œçªƒå–
    pub task_timeout_secs: u64,          // ä»»åŠ¡è¶…æ—¶æ—¶é—´
    pub enable_backpressure: bool,       // å¯ç”¨èƒŒå‹æ§åˆ¶
    pub max_queue_size: usize,           // æœ€å¤§é˜Ÿåˆ—å¤§å°
}

impl Default for ConcurrencyConfig {
    fn default() -> Self {
        let cpu_count = std::thread::available_parallelism()
            .map(|n| n.get())
            .unwrap_or(4);
        Self {
            max_concurrent_tasks: cpu_count * 4,
            worker_threads: cpu_count,
            enable_work_stealing: true,
            task_timeout_secs: 300,  // 5åˆ†é’Ÿ
            enable_backpressure: true,
            max_queue_size: 10000,
        }
    }
}

/// ä»»åŠ¡ä¼˜å…ˆçº§
#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord, Serialize, Deserialize)]
pub enum TaskPriority {
    Critical = 4,
    High = 3,
    Normal = 2,
    Low = 1,
    Background = 0,
}

/// å¼‚æ­¥ä»»åŠ¡
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AsyncTask {
    pub id: String,
    pub name: String,
    pub priority: TaskPriority,
    pub created_at: DateTime<Utc>,
    pub agent_name: Option<String>,
    pub metadata: HashMap<String, String>,
}

/// ä»»åŠ¡ç»“æœ
#[derive(Debug, Clone)]
pub struct TaskResult {
    pub task_id: String,
    pub success: bool,
    pub duration_ms: u64,
    pub error: Option<String>,
}

/// å¹¶å‘ç®¡ç†å™¨
pub struct ConcurrencyManager {
    config: ConcurrencyConfig,
    semaphore: Arc<Semaphore>,
    task_queue: Arc<TokioMutex<VecDeque<AsyncTask>>>,
    running_tasks: Arc<RwLock<HashMap<String, JoinHandle<()>>>>,
    task_results: Arc<RwLock<HashMap<String, TaskResult>>>,
}

impl ConcurrencyManager {
    pub fn new(config: ConcurrencyConfig) -> Self {
        info!("ğŸš€ Concurrency Manager initialized");
        info!("   - Max concurrent: {}", config.max_concurrent_tasks);
        info!("   - Workers: {}", config.worker_threads);
        info!("   - Work stealing: {}", config.enable_work_stealing);

        Self {
            semaphore: Arc::new(Semaphore::new(config.max_concurrent_tasks)),
            task_queue: Arc::new(TokioMutex::new(VecDeque::new())),
            running_tasks: Arc::new(RwLock::new(HashMap::new())),
            task_results: Arc::new(RwLock::new(HashMap::new())),
            config,
        }
    }

    /// æäº¤ä»»åŠ¡
    pub async fn submit_task(&self, task: AsyncTask) -> Result<()> {
        // èƒŒå‹æ§åˆ¶
        if self.config.enable_backpressure {
            let queue_len = self.task_queue.lock().await.len();
            if queue_len >= self.config.max_queue_size {
                warn!("âš ï¸ Task queue full, rejecting task: {}", task.name);
                return Err(anyhow!("Task queue full"));
            }
        }

        let mut queue = self.task_queue.lock().await;
        queue.push_back(task.clone());
        
        info!("ğŸ“¥ Task submitted: {} (priority: {:?})", task.name, task.priority);
        Ok(())
    }

    /// æ‰§è¡Œä¸‹ä¸€ä¸ªä»»åŠ¡
    pub async fn execute_next_task<F, Fut>(&self, executor: F) -> Result<()>
    where
        F: Fn(AsyncTask) -> Fut + Send + 'static,
        Fut: std::future::Future<Output = Result<()>> + Send,
    {
        let task = {
            let mut queue = self.task_queue.lock().await;
            queue.pop_front()
        };

        if let Some(task) = task {
            let permit = self.semaphore.clone().acquire_owned().await?;
            let task_id = task.id.clone();
            let task_name = task.name.clone();
            let results = self.task_results.clone();
            let running = self.running_tasks.clone();

            let start = std::time::Instant::now();

            let task_id_for_map = task_id.clone();

            let handle = tokio::spawn(async move {
                info!("ğŸ”„ Executing task: {}", task_name);

                let result = executor(task.clone()).await;
                let duration = start.elapsed().as_millis() as u64;

                let (success, error) = match result {
                    Ok(_) => (true, None),
                    Err(e) => (false, Some(e.to_string())),
                };

                let task_result = TaskResult {
                    task_id: task_id.clone(),
                    success,
                    duration_ms: duration,
                    error,
                };

                let mut results_guard = results.write().await;
                results_guard.insert(task_id.clone(), task_result);

                let mut running_guard = running.write().await;
                running_guard.remove(&task_id);

                drop(permit);

                if success {
                    info!("âœ… Task completed: {} ({}ms)", task_name, duration);
                } else {
                    error!("âŒ Task failed: {}", task_name);
                }
            });

            let mut running = self.running_tasks.write().await;
            running.insert(task_id_for_map, handle);
        }

        Ok(())
    }

    /// è·å–ä»»åŠ¡ç»“æœ
    pub async fn get_task_result(&self, task_id: &str) -> Option<TaskResult> {
        let results = self.task_results.read().await;
        results.get(task_id).cloned()
    }

    /// è·å–é˜Ÿåˆ—é•¿åº¦
    pub async fn queue_length(&self) -> usize {
        self.task_queue.lock().await.len()
    }

    /// è·å–è¿è¡Œä¸­ä»»åŠ¡æ•°
    pub async fn running_count(&self) -> usize {
        self.running_tasks.read().await.len()
    }

    /// ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
    pub async fn wait_all(&self) -> Result<()> {
        loop {
            let running_count = self.running_count().await;
            let queue_len = self.queue_length().await;

            if running_count == 0 && queue_len == 0 {
                break;
            }

            tokio::time::sleep(tokio::time::Duration::from_millis(100)).await;
        }

        info!("âœ… All tasks completed");
        Ok(())
    }

    /// å–æ¶ˆä»»åŠ¡
    pub async fn cancel_task(&self, task_id: &str) -> Result<()> {
        let mut running = self.running_tasks.write().await;
        
        if let Some(handle) = running.remove(task_id) {
            handle.abort();
            info!("ğŸ›‘ Task cancelled: {}", task_id);
            Ok(())
        } else {
            Err(anyhow!("Task not found: {}", task_id))
        }
    }
}

/// åˆ†å¸ƒå¼é”ï¼ˆç®€åŒ–ç‰ˆï¼Œç”Ÿäº§ç¯å¢ƒåº”ä½¿ç”¨Redisç­‰ï¼‰
pub struct DistributedLock {
    locks: Arc<RwLock<HashMap<String, DateTime<Utc>>>>,
    ttl_secs: u64,
}

impl DistributedLock {
    pub fn new(ttl_secs: u64) -> Self {
        Self {
            locks: Arc::new(RwLock::new(HashMap::new())),
            ttl_secs,
        }
    }

    pub async fn acquire(&self, lock_name: &str) -> Result<bool> {
        let mut locks = self.locks.write().await;

        // æ£€æŸ¥é”æ˜¯å¦å­˜åœ¨ä¸”æœªè¿‡æœŸ
        if let Some(expire_at) = locks.get(lock_name) {
            if Utc::now() < *expire_at {
                return Ok(false); // é”å·²è¢«å ç”¨
            }
        }

        // è·å–é”
        let expire_at = Utc::now() + chrono::Duration::seconds(self.ttl_secs as i64);
        locks.insert(lock_name.to_string(), expire_at);

        debug!("ğŸ”’ Lock acquired: {}", lock_name);
        Ok(true)
    }

    pub async fn release(&self, lock_name: &str) -> Result<()> {
        let mut locks = self.locks.write().await;
        locks.remove(lock_name);

        debug!("ğŸ”“ Lock released: {}", lock_name);
        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_concurrency_manager() {
        let manager = ConcurrencyManager::new(ConcurrencyConfig::default());

        let task = AsyncTask {
            id: "test-task-1".to_string(),
            name: "Test Task".to_string(),
            priority: TaskPriority::Normal,
            created_at: Utc::now(),
            agent_name: None,
            metadata: HashMap::new(),
        };

        manager.submit_task(task).await.unwrap();
        assert_eq!(manager.queue_length().await, 1);
    }

    #[tokio::test]
    async fn test_distributed_lock() {
        let lock = DistributedLock::new(5);

        assert!(lock.acquire("test-lock").await.unwrap());
        assert!(!lock.acquire("test-lock").await.unwrap()); // é‡å¤è·å–åº”å¤±è´¥

        lock.release("test-lock").await.unwrap();
        assert!(lock.acquire("test-lock").await.unwrap()); // é‡Šæ”¾ååº”æˆåŠŸ
    }
}
