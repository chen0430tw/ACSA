// Performance Optimization Module
// æ€§èƒ½ä¼˜åŒ–æ¨¡å— - å¯åŠ¨åŠ é€Ÿå’Œäº‹ä»¶å“åº”ä¼˜åŒ–
//
// æ ¸å¿ƒä¼˜åŒ–ï¼š
// 1. æ‡’åŠ è½½ï¼ˆLazyLockï¼‰- å»¶è¿Ÿåˆå§‹åŒ–é‡é‡çº§å¯¹è±¡
// 2. å¹¶è¡Œåˆå§‹åŒ– - åˆ©ç”¨å¤šæ ¸å¹¶è¡Œå¯åŠ¨
// 3. ç¼“å­˜é¢„çƒ­ - æå‰åŠ è½½å¸¸ç”¨èµ„æº
// 4. äº‹ä»¶å»æŠ–åŠ¨ - é˜²æ­¢é‡å¤è§¦å‘
// 5. å¼‚æ­¥ä¼˜å…ˆçº§è°ƒåº¦ - å…³é”®ä»»åŠ¡ä¼˜å…ˆ

use std::sync::{LazyLock, OnceLock};
use std::time::{Duration, Instant};
use tokio::sync::{Semaphore, RwLock};
use std::collections::HashMap;
use std::sync::Arc;
use tracing::{info, warn, debug};

/// å¯åŠ¨æ€§èƒ½ç»Ÿè®¡
#[derive(Debug, Clone)]
pub struct StartupMetrics {
    /// æ€»å¯åŠ¨æ—¶é—´
    pub total_duration: Duration,
    /// å„é˜¶æ®µè€—æ—¶
    pub phase_durations: HashMap<String, Duration>,
    /// å¹¶è¡Œä»»åŠ¡æ•°
    pub parallel_tasks: usize,
}

/// æ€§èƒ½ä¼˜åŒ–å™¨
pub struct PerformanceOptimizer {
    /// å¯åŠ¨æ—¶é—´è·Ÿè¸ª
    startup_time: Instant,
    /// é˜¶æ®µè€—æ—¶è®°å½•
    phase_times: Arc<RwLock<HashMap<String, Duration>>>,
    /// äº‹ä»¶å»æŠ–åŠ¨é™åˆ¶å™¨
    debounce_limiter: Arc<Semaphore>,
}

impl PerformanceOptimizer {
    /// åˆ›å»ºæ€§èƒ½ä¼˜åŒ–å™¨
    pub fn new() -> Self {
        info!("ğŸš€ Performance Optimizer initialized");
        Self {
            startup_time: Instant::now(),
            phase_times: Arc::new(RwLock::new(HashMap::new())),
            debounce_limiter: Arc::new(Semaphore::new(10)), // æœ€å¤š10ä¸ªå¹¶å‘äº‹ä»¶
        }
    }

    /// è®°å½•é˜¶æ®µå¼€å§‹
    pub async fn start_phase(&self, phase_name: &str) -> PhaseTracker {
        debug!("â±ï¸  Starting phase: {}", phase_name);
        PhaseTracker {
            name: phase_name.to_string(),
            start: Instant::now(),
            phase_times: self.phase_times.clone(),
        }
    }

    /// è·å–å¯åŠ¨æŒ‡æ ‡
    pub async fn get_startup_metrics(&self) -> StartupMetrics {
        let total_duration = self.startup_time.elapsed();
        let phase_durations = self.phase_times.read().await.clone();
        let parallel_tasks = phase_durations.len();

        StartupMetrics {
            total_duration,
            phase_durations,
            parallel_tasks,
        }
    }

    /// äº‹ä»¶å»æŠ–åŠ¨ï¼ˆé˜²æ­¢é‡å¤è§¦å‘ï¼‰
    pub async fn debounce_event<F, Fut, T>(
        &self,
        event_handler: F,
    ) -> Option<T>
    where
        F: FnOnce() -> Fut,
        Fut: std::future::Future<Output = T>,
    {
        // å°è¯•è·å–è®¸å¯ï¼ˆéé˜»å¡ï¼‰
        if let Ok(permit) = self.debounce_limiter.clone().try_acquire_owned() {
            let result = event_handler().await;
            drop(permit); // é‡Šæ”¾è®¸å¯
            Some(result)
        } else {
            warn!("âš ï¸  Event dropped due to debounce limit");
            None
        }
    }

    /// å¹¶è¡Œåˆå§‹åŒ–ï¼ˆåŠ é€Ÿå¯åŠ¨ï¼‰
    pub async fn parallel_init<F, Fut>(tasks: Vec<(&str, F)>) -> Vec<anyhow::Result<()>>
    where
        F: FnOnce() -> Fut + Send + 'static,
        Fut: std::future::Future<Output = anyhow::Result<()>> + Send,
    {
        info!("ğŸ”„ Starting {} parallel initialization tasks", tasks.len());

        let handles: Vec<_> = tasks
            .into_iter()
            .map(|(name, task)| {
                let name = name.to_string();
                tokio::spawn(async move {
                    let start = Instant::now();
                    info!("  â³ Initializing: {}", name);
                    let result = task().await;
                    let elapsed = start.elapsed();
                    match &result {
                        Ok(_) => info!("  âœ… Initialized {} in {:?}", name, elapsed),
                        Err(e) => warn!("  âŒ Failed to initialize {}: {}", name, e),
                    }
                    result
                })
            })
            .collect();

        let mut results = Vec::new();
        for handle in handles {
            match handle.await {
                Ok(result) => results.push(result),
                Err(e) => results.push(Err(anyhow::anyhow!("Task panicked: {}", e))),
            }
        }

        results
    }
}

impl Default for PerformanceOptimizer {
    fn default() -> Self {
        Self::new()
    }
}

/// é˜¶æ®µè·Ÿè¸ªå™¨ï¼ˆè‡ªåŠ¨è®°å½•è€—æ—¶ï¼‰
pub struct PhaseTracker {
    name: String,
    start: Instant,
    phase_times: Arc<RwLock<HashMap<String, Duration>>>,
}

impl Drop for PhaseTracker {
    fn drop(&mut self) {
        let elapsed = self.start.elapsed();
        debug!("  âœ“ Phase '{}' completed in {:?}", self.name, elapsed);

        // å¼‚æ­¥è®°å½•ï¼ˆéé˜»å¡ï¼‰
        let name = self.name.clone();
        let phase_times = self.phase_times.clone();
        tokio::spawn(async move {
            phase_times.write().await.insert(name, elapsed);
        });
    }
}

/// æ‡’åŠ è½½ç¤ºä¾‹ï¼ˆä½¿ç”¨ std::sync::LazyLockï¼‰
///
/// ç”¨æ³•ç¤ºä¾‹ï¼š
/// ```
/// use std::sync::LazyLock;
///
/// static HEAVY_RESOURCE: LazyLock<HeavyResource> = LazyLock::new(|| {
///     HeavyResource::initialize()
/// });
/// ```

/// ç¼“å­˜é¢„çƒ­å™¨
pub struct CacheWarmer {
    /// é¢„çƒ­ä»»åŠ¡åˆ—è¡¨
    tasks: Vec<Box<dyn FnOnce() -> () + Send>>,
}

impl CacheWarmer {
    /// åˆ›å»ºç¼“å­˜é¢„çƒ­å™¨
    pub fn new() -> Self {
        Self { tasks: Vec::new() }
    }

    /// æ·»åŠ é¢„çƒ­ä»»åŠ¡
    pub fn add_task<F>(&mut self, task: F)
    where
        F: FnOnce() -> () + Send + 'static,
    {
        self.tasks.push(Box::new(task));
    }

    /// æ‰§è¡Œé¢„çƒ­ï¼ˆåå°å¼‚æ­¥ï¼‰
    pub fn warm_up(self) {
        info!("ğŸ”¥ Starting cache warm-up with {} tasks", self.tasks.len());

        tokio::spawn(async move {
            for (i, task) in self.tasks.into_iter().enumerate() {
                task();
                debug!("  âœ“ Warm-up task {} completed", i + 1);
            }
            info!("âœ… Cache warm-up completed");
        });
    }
}

impl Default for CacheWarmer {
    fn default() -> Self {
        Self::new()
    }
}

/// äº‹ä»¶æ‰¹å¤„ç†å™¨ï¼ˆä¼˜åŒ–æŒ‰é’®å“åº”ï¼‰
pub struct EventBatcher<T: Send> {
    /// å¾…å¤„ç†äº‹ä»¶
    pending: Arc<RwLock<Vec<T>>>,
}

impl<T: Send + 'static> EventBatcher<T> {
    /// åˆ›å»ºäº‹ä»¶æ‰¹å¤„ç†å™¨
    pub fn new() -> Self {
        Self {
            pending: Arc::new(RwLock::new(Vec::new())),
        }
    }

    /// æ·»åŠ äº‹ä»¶åˆ°æ‰¹æ¬¡
    pub async fn add_event(&self, event: T) {
        self.pending.write().await.push(event);
    }

    /// è·å–å¹¶æ¸…ç©ºå½“å‰æ‰¹æ¬¡ï¼ˆæ‰‹åŠ¨æ‰¹å¤„ç†ï¼‰
    pub async fn take_batch(&self) -> Vec<T> {
        let mut guard = self.pending.write().await;
        std::mem::take(&mut *guard)
    }

    /// è·å–å½“å‰æ‰¹æ¬¡å¤§å°
    pub async fn batch_size(&self) -> usize {
        self.pending.read().await.len()
    }
}

impl<T: Send + 'static> Default for EventBatcher<T> {
    fn default() -> Self {
        Self::new()
    }
}

type TaskBox = Box<dyn FnOnce() -> () + Send>;

/// ä¼˜å…ˆçº§ä»»åŠ¡è°ƒåº¦å™¨
pub struct PriorityScheduler {
    high_priority: Arc<tokio::sync::mpsc::UnboundedSender<TaskBox>>,
    low_priority: Arc<tokio::sync::mpsc::UnboundedSender<TaskBox>>,
}

impl PriorityScheduler {
    /// åˆ›å»ºä¼˜å…ˆçº§è°ƒåº¦å™¨
    pub fn new() -> Self {
        let (high_tx, mut high_rx) = tokio::sync::mpsc::unbounded_channel::<TaskBox>();
        let (low_tx, mut low_rx) = tokio::sync::mpsc::unbounded_channel::<TaskBox>();

        // é«˜ä¼˜å…ˆçº§ä»»åŠ¡å¤„ç†å™¨
        tokio::spawn(async move {
            while let Some(task) = high_rx.recv().await {
                task();
            }
        });

        // ä½ä¼˜å…ˆçº§ä»»åŠ¡å¤„ç†å™¨
        tokio::spawn(async move {
            while let Some(task) = low_rx.recv().await {
                task();
            }
        });

        Self {
            high_priority: Arc::new(high_tx),
            low_priority: Arc::new(low_tx),
        }
    }

    /// æäº¤é«˜ä¼˜å…ˆçº§ä»»åŠ¡ï¼ˆç«‹å³æ‰§è¡Œï¼‰
    pub fn submit_high<F>(&self, task: F)
    where
        F: FnOnce() -> () + Send + 'static,
    {
        let _ = self.high_priority.send(Box::new(task));
    }

    /// æäº¤ä½ä¼˜å…ˆçº§ä»»åŠ¡ï¼ˆåå°æ‰§è¡Œï¼‰
    pub fn submit_low<F>(&self, task: F)
    where
        F: FnOnce() -> () + Send + 'static,
    {
        let _ = self.low_priority.send(Box::new(task));
    }
}

impl Default for PriorityScheduler {
    fn default() -> Self {
        Self::new()
    }
}

/// å…¨å±€æ€§èƒ½ä¼˜åŒ–å™¨å®ä¾‹ï¼ˆæ‡’åŠ è½½ï¼‰
pub static GLOBAL_OPTIMIZER: LazyLock<PerformanceOptimizer> =
    LazyLock::new(|| PerformanceOptimizer::new());

/// å…¨å±€ä¼˜å…ˆçº§è°ƒåº¦å™¨å®ä¾‹ï¼ˆæ‡’åŠ è½½ï¼‰
pub static GLOBAL_SCHEDULER: LazyLock<PriorityScheduler> =
    LazyLock::new(|| PriorityScheduler::new());

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_phase_tracking() {
        let optimizer = PerformanceOptimizer::new();

        {
            let _phase = optimizer.start_phase("test_phase").await;
            tokio::time::sleep(Duration::from_millis(10)).await;
        }

        tokio::time::sleep(Duration::from_millis(50)).await; // ç­‰å¾…å¼‚æ­¥è®°å½•

        let metrics = optimizer.get_startup_metrics().await;
        assert!(metrics.phase_durations.contains_key("test_phase"));
    }

    #[tokio::test]
    async fn test_debounce() {
        let optimizer = PerformanceOptimizer::new();

        let result = optimizer.debounce_event(|| async { 42 }).await;
        assert_eq!(result, Some(42));
    }

    #[tokio::test]
    async fn test_parallel_init() {
        let tasks = vec![
            ("task1", || async { Ok(()) }),
            ("task2", || async { Ok(()) }),
        ];

        let results = PerformanceOptimizer::parallel_init(tasks).await;
        assert_eq!(results.len(), 2);
        assert!(results.iter().all(|r| r.is_ok()));
    }
}
